{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book 5 (Categorizing and Tagging Words)\n",
    "#### SIDE-39-GAB\n",
    "#### Bastomy - 1301178418 - Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Categorizing and Tagging Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag yang di sediakan nltk adalah sebagai berikut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pos_tagging.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1   Using a Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk memberikan library untuk Pos-Tagging , dimana pos tagging ini membutuhkan input berupa token, untuk contoh penggunaanya dapat di lihat pada kode dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('very', 'RB'), ('happy', 'JJ'), ('right', 'NN'), ('now', 'RB')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"I very happy right now\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agar penggunaan lebih mudah kita akan membuat sebuah fungsi untuk menggunakan pos-tagging tersebut, seperti kode dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(string):\n",
    "    token = word_tokenize(string)\n",
    "    return nltk.pos_tag(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Nice', 'NNP'), ('to', 'TO'), ('meet', 'VB'), ('you', 'PRP'), ('!', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagging(\"Nice to meet you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagging(\"They refuse to permit us to obtain the refuse permit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada kode dibawah kita akan menggunakan words yang di sediakan korpus brown dan mencari similarity nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black and good strong time learned true young clear proud the is one\n",
      "seen all there more made about research\n"
     ]
    }
   ],
   "source": [
    "text.similar('handsome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the used important available there reasonable made good high needed\n",
      "assigned is effective seen not fair his out registered first\n"
     ]
    }
   ],
   "source": [
    "text.similar(\"excellent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that made and not just good much important possible it all told right\n",
      "necessary in for on there left close\n"
     ]
    }
   ],
   "source": [
    "text.similar('happy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2   Tagged Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1   Representing Tagged Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kita bisa menambahkan tag dan kata yang kita mau sendiri dengan menggunakan kode dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token = nltk.tag.str2tuple('fly/NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fly', 'NN')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_token = nltk.tag.str2tuple('pintar/JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pintar', 'JJ')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pintar\n",
      "JJ\n"
     ]
    }
   ],
   "source": [
    "print(tagged_token[0])\n",
    "print(tagged_token[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2   Reading Tagged Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk mencari tag set dalam corpus brown kita bisa menggunakan kode dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'UNK'), ('Fulton', 'UNK'), ('County', 'UNK'), ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_words(tagset='smart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'UNK'), ('Fulton', 'UNK'), ('County', 'UNK'), ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_words(tagset='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag dari corpus nps_chat yang disediakan nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('now', 'RB'), ('im', 'PRP'), ('left', 'VBD'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.nps_chat.tagged_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.conll2000.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.treebank.tagged_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3   A Universal Part-of-Speech Tagset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"universal_pos.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk melihat tag yang paling sering muncul di categori tertentu dalam corpus brown kita bisa menggunakan kode di bawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 30654),\n",
       " ('VERB', 14399),\n",
       " ('ADP', 12355),\n",
       " ('.', 11928),\n",
       " ('DET', 11389),\n",
       " ('ADJ', 6706),\n",
       " ('ADV', 3349),\n",
       " ('CONJ', 2717),\n",
       " ('PRON', 2535),\n",
       " ('PRT', 2264),\n",
       " ('NUM', 2166),\n",
       " ('X', 92)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
    "tag_fd.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4   Nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada tag juga bisa digunakan bigram dimana pasangan tag yang paling sering muncul akan membuat kemungikinan tag tersebut semakin besar untuk terpilih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " '.',\n",
       " 'VERB',\n",
       " 'CONJ',\n",
       " 'NUM',\n",
       " 'ADV',\n",
       " 'PRT',\n",
       " 'PRON',\n",
       " 'X']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
    "noun_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'NOUN']\n",
    "fdist = nltk.FreqDist(noun_preceders)\n",
    "[tag for (tag, _) in fdist.most_common()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urutan tag yang paling sering untuk NOUN dapat di lihat pada kode di atas mulai dari NOUN DET sampai dengan X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'VERB',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " '.',\n",
       " 'ADV',\n",
       " 'DET',\n",
       " 'CONJ',\n",
       " 'ADP',\n",
       " 'ADJ',\n",
       " 'NUM',\n",
       " 'X']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
    "noun_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'VERB']\n",
    "fdist = nltk.FreqDist(noun_preceders)\n",
    "[tag for (tag, _) in fdist.most_common()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urutan tag yang paling sering untuk VERB dapat di lihat pada kode di atas mulai dari NOUN VERB sampai dengan X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5   Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj = nltk.corpus.treebank.tagged_words(tagset='universal')\n",
    "word_tag_fd = nltk.FreqDist(wsj)\n",
    "data = [wt[0] for (wt, _) in word_tag_fd.most_common() if wt[1] == 'VERB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kata yang paling sering muncul dari verb adalah sebagai berikut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'said', 'was', 'are', 'be', 'has', 'have', 'will', 'says', 'would']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk mengecek kata lainnya kita tinggal merubah isi dari VERB tersebut sesuai dengan tag yang ingin di cari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj = nltk.corpus.treebank.tagged_words(tagset='universal')\n",
    "word_tag_fd = nltk.FreqDist(wsj)\n",
    "data = [wt[0] for (wt, _) in word_tag_fd.most_common() if wt[1] == 'NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['%',\n",
       " 'Mr.',\n",
       " 'company',\n",
       " 'U.S.',\n",
       " 'year',\n",
       " 'market',\n",
       " 'New',\n",
       " 'trading',\n",
       " 'stock',\n",
       " 'president']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VERB', 28), ('NOUN', 20)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd1 = nltk.ConditionalFreqDist(wsj)\n",
    "cfd1['yield'].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VERB', 25), ('NOUN', 3)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd1['cut'].most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ada cara lain untuk mencari tag yang paling sering muncul yaitu menggunakan cfd atau ConditionalFreqDist, kita tinggal memanggil seperti kode dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 3)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd1['task'].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj = nltk.corpus.treebank.tagged_words()\n",
    "cfd2 = nltk.ConditionalFreqDist((tag, word) for (word, tag) in wsj)\n",
    "data = list(cfd2['VBN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['named',\n",
       " 'used',\n",
       " 'caused',\n",
       " 'exposed',\n",
       " 'reported',\n",
       " 'replaced',\n",
       " 'sold',\n",
       " 'died',\n",
       " 'expected',\n",
       " 'diagnosed']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6   Adjectives and Adverbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dua kelas kata penting lainnya adalah kata sifat dan kata keterangan. Kata sifat menggambarkan kata benda, dan dapat digunakan sebagai pengubah (mis. Besar di pizza besar), atau dalam predikat (mis. Pizza besar). Kata sifat Bahasa Inggris dapat memiliki struktur internal (mis. Jatuh + dalam stok yang jatuh). Adverbia memodifikasi kata kerja untuk menentukan waktu, cara, tempat atau arah acara yang dijelaskan oleh kata kerja (mis. Cepat dalam stok jatuh dengan cepat). Adverbia juga dapat mengubah kata sifat (mis. Benar-benar menurut guru Mary sangat bagus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7   Unsimplified Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fungsi di bawah adalah untuk mencari tag dalam corpus berdasarkan kategori tertentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findtags(tag_prefix, tagged_text):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
    "                                  if tag.startswith(tag_prefix))\n",
    "    return dict((tag, cfd[tag].most_common(5)) for tag in cfd.conditions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mencari tag NN dengan categori news pada korpus brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagdict = findtags('NN', nltk.corpus.brown.tagged_words(categories='news'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN [('year', 137), ('time', 97), ('state', 88), ('week', 85), ('man', 72)]\n",
      "NN$ [(\"year's\", 13), (\"world's\", 8), (\"state's\", 7), (\"nation's\", 6), (\"city's\", 6)]\n",
      "NN$-HL [(\"Golf's\", 1), (\"Navy's\", 1)]\n",
      "NN$-TL [(\"President's\", 11), (\"Administration's\", 3), (\"Army's\", 3), (\"League's\", 3), (\"University's\", 3)]\n",
      "NN-HL [('sp.', 2), ('problem', 2), ('Question', 2), ('cut', 2), ('party', 2)]\n",
      "NN-NC [('ova', 1), ('eva', 1), ('aya', 1)]\n",
      "NN-TL [('President', 88), ('House', 68), ('State', 59), ('University', 42), ('City', 41)]\n",
      "NN-TL-HL [('Fort', 2), ('Mayor', 1), ('Commissioner', 1), ('City', 1), ('Oak', 1)]\n",
      "NNS [('years', 101), ('members', 69), ('people', 52), ('sales', 51), ('men', 46)]\n",
      "NNS$ [(\"children's\", 7), (\"women's\", 5), (\"men's\", 3), (\"janitors'\", 3), (\"taxpayers'\", 2)]\n",
      "NNS$-HL [(\"Dealers'\", 1), (\"Idols'\", 1)]\n",
      "NNS$-TL [(\"Women's\", 4), (\"States'\", 3), (\"Giants'\", 2), (\"Princes'\", 1), (\"Bombers'\", 1)]\n",
      "NNS-HL [('Wards', 1), ('deputies', 1), ('bonds', 1), ('aspects', 1), ('Decisions', 1)]\n",
      "NNS-TL [('States', 38), ('Nations', 11), ('Masters', 10), ('Communists', 9), ('Rules', 9)]\n",
      "NNS-TL-HL [('Nations', 1)]\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(tagdict):\n",
    "    print(tag, tagdict[tag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh lainnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagdict = findtags('JJ', nltk.corpus.brown.tagged_words(categories='news'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ [('new', 147), ('such', 51), ('good', 45), ('high', 43), ('American', 40)]\n",
      "JJ-HL [('special', 4), ('modest', 2), ('New', 2), ('prejudicial', 1), ('Exploratory', 1)]\n",
      "JJ-NC [('dull', 1)]\n",
      "JJ-TL [('New', 88), ('National', 39), ('Democratic', 35), ('White', 34), ('North', 28)]\n",
      "JJR [('higher', 23), ('better', 17), ('greater', 10), ('further', 10), ('earlier', 7)]\n",
      "JJR-HL [('higher', 1), ('lighter', 1), ('Younger', 1), ('Easier', 1)]\n",
      "JJR-NC [('Calmer', 1)]\n",
      "JJR-TL [('Greater', 2), ('Better', 1), ('Elder', 1)]\n",
      "JJS [('top', 23), ('chief', 6), ('principal', 5), ('key', 4), ('main', 3)]\n",
      "JJS-TL [('Chief', 2)]\n",
      "JJT [('best', 26), ('largest', 10), ('greatest', 9), ('biggest', 9), ('highest', 6)]\n",
      "JJT-HL [('best', 1), ('highest', 1)]\n"
     ]
    }
   ],
   "source": [
    "for tag in sorted(tagdict):\n",
    "    print(tag, tagdict[tag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8   Exploring Tagged Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " 'accomplished',\n",
       " 'analytically',\n",
       " 'appear',\n",
       " 'apt',\n",
       " 'associated',\n",
       " 'assuming',\n",
       " 'became',\n",
       " 'become',\n",
       " 'been',\n",
       " 'began',\n",
       " 'call',\n",
       " 'called',\n",
       " 'carefully',\n",
       " 'chose',\n",
       " 'classified',\n",
       " 'colorful',\n",
       " 'composed',\n",
       " 'contain',\n",
       " 'differed',\n",
       " 'difficult',\n",
       " 'encountered',\n",
       " 'enough',\n",
       " 'equate',\n",
       " 'extremely',\n",
       " 'found',\n",
       " 'happens',\n",
       " 'have',\n",
       " 'ignored',\n",
       " 'in',\n",
       " 'involved',\n",
       " 'more',\n",
       " 'needed',\n",
       " 'nightly',\n",
       " 'observed',\n",
       " 'of',\n",
       " 'on',\n",
       " 'out',\n",
       " 'quite',\n",
       " 'represent',\n",
       " 'responsible',\n",
       " 'revamped',\n",
       " 'seclude',\n",
       " 'set',\n",
       " 'shortened',\n",
       " 'sing',\n",
       " 'sounded',\n",
       " 'stated',\n",
       " 'still',\n",
       " 'sung',\n",
       " 'supported',\n",
       " 'than',\n",
       " 'to',\n",
       " 'when',\n",
       " 'work']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_learned_text = brown.words(categories='learned')\n",
    "sorted(set(b for (a, b) in nltk.bigrams(brown_learned_text) if a == 'often'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mengecek kata tertentu dan menghitung kemunculan tag tersebut, contoh kode seperti dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB  ADV  ADP  ADJ    .  PRT \n",
      "  37    8    7    6    4    2 \n"
     ]
    }
   ],
   "source": [
    "brown_lrnd_tagged = brown.tagged_words(categories='learned', tagset='universal')\n",
    "tags = [b[1] for (a, b) in nltk.bigrams(brown_lrnd_tagged) if a[0] == 'often']\n",
    "fd = nltk.FreqDist(tags)\n",
    "fd.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kata often muncul sebanyak 37 kali dalam tag VERB dan lainnnya, berikut untuk contoh lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   .  ADV CONJ \n",
      "   2    1    1 \n"
     ]
    }
   ],
   "source": [
    "brown_lrnd_tagged = brown.tagged_words(categories='learned', tagset='universal')\n",
    "tags = [b[1] for (a, b) in nltk.bigrams(brown_lrnd_tagged) if a[0] == 'happy']\n",
    "fd = nltk.FreqDist(tags)\n",
    "fd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "data = nltk.ConditionalFreqDist((word.lower(), tag)\n",
    "                                for (word, tag) in brown_news_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ADJ ADV VERB NOUN\n",
      "close ADV ADJ VERB NOUN\n",
      "open ADJ VERB NOUN ADV\n",
      "present ADJ ADV NOUN VERB\n",
      "that ADP DET PRON ADV\n"
     ]
    }
   ],
   "source": [
    "for word in sorted(data.conditions()):\n",
    "    if len(data[word]) > 3:\n",
    "        tags = [tag for (tag, _) in data[word].most_common()]\n",
    "        print(word, ' '.join(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3   Mapping Words to Properties Using Python Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1   Indexing Lists vs Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"maps02.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"linguistic.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2   Dictionaries in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kita bisa menambahkan dictiionari pada python dengan memanfaatkan object, contoh pada kode di bawah kita menggunakan colorless sebagai index dan ADJ sebagai isinya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {}\n",
    "pos['colorless'] = 'ADJ'\n",
    "pos['apple'] = 'N'\n",
    "pos['ideas'] = 'N'\n",
    "pos['water'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colorless': 'ADJ', 'apple': 'N', 'ideas': 'N', 'water': 'N'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk menampilkan list dari pos bisa menggunakan perintah <b> list</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colorless', 'apple', 'ideas', 'water']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple: N\n",
      "colorless: ADJ\n",
      "ideas: N\n",
      "water: N\n"
     ]
    }
   ],
   "source": [
    "for word in sorted(pos):\n",
    "    print(word + \":\", pos[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk menampilkan value dari pos bisa menggunakan perintah <b>values()</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADJ', 'N', 'N', 'N']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pos.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk menampilkan index atau key dari pos bisa menggunakan perintah <b>keys()</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colorless', 'apple', 'ideas', 'water']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pos.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk menampilkan keduanya bisa menggunakan perintah <b>intems()</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('colorless', 'ADJ'), ('apple', 'N'), ('ideas', 'N'), ('water', 'N')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pos.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3   Defining Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ada 2 cara pendefinisian dictionary yaitu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cara kedua "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = dict(colorless='ADJ', ideas='N', sleep='V', furiously='ADV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4   Default Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "secara default python akan memberi nilai 0 untuk index yang tidak di temukan seperti pada contoh di bawah, hal ini berguna untuk menghindari error apabila index atau key tidak ditemukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "frequency['colorless'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency['colorless']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency['ideas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = nltk.corpus.gutenberg.words('carroll-alice.txt')\n",
    "vocab = nltk.FreqDist(alice)\n",
    "v1000 = [word for (word, _) in vocab.most_common(1000)]\n",
    "mapping = defaultdict(lambda: 'UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in v1000:\n",
    "    mapping[v] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'UNK', 'UNK', 'UNK', 'UNK', 'CHAPTER', 'I', '.', 'Down', 'the', 'Rabbit', '-', 'UNK', 'Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing']\n"
     ]
    }
   ],
   "source": [
    "alice2 = [mapping[v] for v in alice]\n",
    "print(alice2[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(alice2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5   Incrementally Updating a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8876"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = ('NN', 8876)\n",
    "pair[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk membuat pengecekan kata akhir kita akan membutuhkan sebuah korpus untuk data tes, disini kita menggunakan corpus bahasa inggris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_letters = defaultdict(list)\n",
    "words = nltk.corpus.words.words('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada perulangan dibawah akan di cek -2 artinya 2 karakter terakhir akan di cocokan untuk mendapatkan akhiran suatu kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    key = word[-2:]\n",
    "    last_letters[key].append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contoh kata yang berakhiran <b>ly</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abactinally', 'abandonedly', 'abasedly', 'abashedly', 'abashlessly', 'abbreviately', 'abdominally', 'abhorrently', 'abidingly', 'abiogenetically']\n"
     ]
    }
   ],
   "source": [
    "data = last_letters['ly']\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contoh kata yang berakhiran <b>st</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abacist', 'abdest', 'abiogenesist', 'abiogenist', 'ablest', 'abnormalist', 'abolitionist', 'abortionist', 'abreast', 'absolutist', 'abstentionist', 'abstractionist', 'aburst', 'academist', 'acarologist']\n"
     ]
    }
   ],
   "source": [
    "data = last_letters['st']\n",
    "print(data[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>anagram</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagrams = defaultdict(list)\n",
    "for word in words:\n",
    "    key = ''.join(sorted(word))\n",
    "    anagrams[key].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entrail', 'latrine', 'ratline', 'reliant', 'retinal', 'trenail']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams['aeilnrt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contoh lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hypha']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams['ahhpy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6   Complex Keys and Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = defaultdict(lambda: defaultdict(int))\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ((w1, t1), (w2, t2)) in nltk.bigrams(brown_news_tagged):\n",
    "    pos[(t1, w2)][t2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'NOUN': 5, 'ADJ': 11})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[('DET', 'right')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7   Inverting a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = defaultdict(int)\n",
    "for word in nltk.corpus.gutenberg.words('milton-paradise.txt'):\n",
    "    counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whence', 'These', 'face', 'divine', 'too']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for (key, value) in counts.items() if value == 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chaos',\n",
       " 'cause',\n",
       " 'High',\n",
       " 'fiery',\n",
       " 'wrath',\n",
       " 'hate',\n",
       " 'winds',\n",
       " 'Be',\n",
       " 'serve',\n",
       " 'ease',\n",
       " 'Whose',\n",
       " 'sacred',\n",
       " 'hands',\n",
       " 'Maker',\n",
       " 'Far',\n",
       " 'Each',\n",
       " 'fight',\n",
       " 'law',\n",
       " 'creatures',\n",
       " 'back']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for (key, value) in counts.items() if value == 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}\n",
    "pos2 = dict((value, key) for (key, value) in pos.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N ideas\n",
      "V sleep\n"
     ]
    }
   ],
   "source": [
    "print(\"N\",pos2['N'])\n",
    "print(\"V\",pos2['V'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.update({'cats': 'N', 'scratch': 'V', 'peacefully': 'ADV', 'old': 'ADJ'})\n",
    "pos2 = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in pos.items():\n",
    "    pos2[value].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADV ['furiously', 'peacefully']\n",
      "ADJ ['colorless', 'old']\n"
     ]
    }
   ],
   "source": [
    "print(\"ADV\",pos2['ADV'])\n",
    "print(\"ADJ\",pos2['ADJ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4   Automatic Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
